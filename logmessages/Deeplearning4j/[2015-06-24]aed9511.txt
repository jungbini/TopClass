  Still WIP and a lot packed into this update unfortunately. Key fixes centered in MultiLayer and BaseLayer. Differentiate between two approaches to calc output change based on loss function. Actually capture the results for adjusted gradient and actually apply them to paramers in update. Fix made to feedforward and how the results are captured in the activation and derivative lists. Some tests in BackPropMLP are still failing but the expected and actual are close again. Several other files updated were due to change in loop for gradient adjustment in multilayer which changed parameters in many places where update is referenced. In future need to consolidate gradient adjustment into default gradient for a cleaner flow.  